## Image Captioning Using Transformers
Image Captioning using Deep Learning: 

• Developed an image captioning system based on the encoder-decoder model using the Transformer architecture


• Utilized a pre-trained Vision Transformer (ViT) model to encode images and extract meaningful embeddings and
implemented the decoder’s key components from scratch, leveraging TensorFlow’s Input and Embedding layers


• Trained the model on the Flicker8k benchmark, optimized it’s performance through hyperparameter tuning and
evaluated the performance by employing the widely used BLEU metric, obtaining a BLUE-2 score of 0.34

Dataset : https://www.kaggle.com/datasets/adityajn105/flickr8k

The main aim of this project was to gain proficieny in Python as well understand the working of the widely used transformer architecture by implementing it from scratch using Tensorflow
